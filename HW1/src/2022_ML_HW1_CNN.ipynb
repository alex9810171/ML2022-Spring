{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2022_ML_HW1_CNN.ipynb","provenance":[],"authorship_tag":"ABX9TyO3C+xTjad8DSkQ1jS6vB0Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy\n","import torch\n","\n","X = numpy.random.uniform(-10, 10, 70).reshape(1, 7, -1)\n","# Y = np.random.randint(0, 9, 10).reshape(1, 1, -1)\n","\n","class Simple1DCNN(torch.nn.Module):\n","    def __init__(self):\n","        super(Simple1DCNN, self).__init__()\n","        self.layer1 = torch.nn.Conv1d(in_channels=7, out_channels=20, kernel_size=5, stride=2)\n","        self.act1 = torch.nn.ReLU()\n","        self.layer2 = torch.nn.Conv1d(in_channels=20, out_channels=10, kernel_size=1)\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.act1(x)\n","        x = self.layer2(x)\n","\n","        log_probs = torch.nn.functional.log_softmax(x, dim=1)\n","\n","        return log_probs\n","\n","model = Simple1DCNN().double()\n","print(model(torch.tensor(X)).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbVvqOIAXuuF","executionInfo":{"status":"ok","timestamp":1645549988796,"user_tz":-480,"elapsed":1,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"59ee1e78-2bba-42ee-f388-6699b2eb0f60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 10, 3])\n"]}]},{"cell_type":"code","source":["X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEXFOmmfX8Ex","executionInfo":{"status":"ok","timestamp":1645549989219,"user_tz":-480,"elapsed":2,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"1f936efc-97f4-4c4e-c6d4-9a89f69ec6ed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 7, 10)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XW3fG6OGIf0K","executionInfo":{"status":"ok","timestamp":1645549989565,"user_tz":-480,"elapsed":347,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"3d3a5429-46f4-4518-bd9c-add4d6efd27a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!gdown --id '1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS' --output covid.train.csv\n","!gdown --id '1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg' --output covid.test.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCYZ9FYUJLuv","executionInfo":{"status":"ok","timestamp":1645549991624,"user_tz":-480,"elapsed":2061,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"31328741-50c5-4aba-ef17-da1895e8359d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS\n","To: /content/covid.train.csv\n","100% 2.49M/2.49M [00:00<00:00, 188MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg\n","To: /content/covid.test.csv\n","100% 993k/993k [00:00<00:00, 135MB/s]\n"]}]},{"cell_type":"code","source":["# Numerical Operations\n","import math\n","import numpy as np\n","\n","# Reading/Writing Data\n","import pandas as pd\n","import os\n","import csv\n","\n","# For Progress Bar\n","from tqdm import tqdm\n","\n","# Pytorch\n","import torch \n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","# For plotting learning curve\n","from torch.utils.tensorboard import SummaryWriter"],"metadata":{"id":"3u3maa-2I7In"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def same_seed(seed): \n","    '''Fixes random number generator seeds for reproducibility.'''\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","\n","def train_valid_split(data_set, valid_ratio, seed):\n","    '''Split provided training data into training set and validation set'''\n","    valid_set_size = int(valid_ratio * len(data_set)) \n","    train_set_size = len(data_set) - valid_set_size\n","    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n","    return np.array(train_set), np.array(valid_set)\n","\n","def predict(test_loader, model, device):\n","    model.eval() # Set your model to evaluation mode.\n","    preds = []\n","    for x in tqdm(test_loader):\n","        x = x.to(device)                        \n","        with torch.no_grad():                   \n","            pred = model(x)                     \n","            preds.append(pred.detach().cpu())   \n","    preds = torch.cat(preds, dim=0).numpy()  \n","    return preds"],"metadata":{"id":"LCQSU_M-JPdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class COVID19Dataset(Dataset):\n","    '''\n","    x: Features.\n","    y: Targets, if none, do prediction.\n","    '''\n","    def __init__(self, x, y=None):\n","        if y is None:\n","            self.y = y\n","        else:\n","            self.y = torch.FloatTensor(y)\n","        self.x = torch.FloatTensor(x)\n","\n","    def __getitem__(self, idx):\n","        if self.y is None:\n","            return self.x[idx]\n","        else:\n","            return self.x[idx], self.y[idx]\n","\n","    def __len__(self):\n","        return len(self.x)"],"metadata":{"id":"W-lRfn-xJQoO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim):\n","        super(My_Model, self).__init__()\n","        # TODO: modify model's structure, be aware of dimensions. \n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 1),\n","            nn.ReLU(),\n","            nn.Linear(64, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = x.squeeze(1) # (B, 1) -> (B)\n","        return x"],"metadata":{"id":"bJEatZYEJYWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_selection import VarianceThreshold\n","\n","def select_feat(train_data, valid_data, test_data, select_all=True):\n","    '''Selects useful features to perform regression'''\n","    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n","    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n","\n","    if select_all:\n","        feat_idx = list(range(raw_x_train.shape[1]))\n","    else:\n","        feat_idx = [38,54,70,86,102,\n","               39,55,71,87,103,\n","               40,56,72,88,104,\n","               41,57,73,89,105,\n","               42,58,74,90,106,\n","               43,59,75,91,107,\n","               44,60,76,92,108,\n","               45,61,77,93,109,\n","               46,62,78,94,110,\n","               47,63,79,95,111,\n","               48,64,80,96,112,\n","               49,65,81,97,113,\n","               50,66,82,98,114,\n","               51,67,83,99,115,\n","               52,68,84,100,116,\n","               53,69,85,101]\n","          \n","    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"],"metadata":{"id":"ZtMMU97uJlda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def trainer(train_loader, valid_loader, model, config, device):\n","\n","    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n","\n","    # Define your optimization algorithm. \n","    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n","    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=0.001)\n","\n","    writer = SummaryWriter() # Writer of tensoboard.\n","\n","    if not os.path.isdir('./models'):\n","        os.mkdir('./models') # Create directory of saving models.\n","\n","    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train() # Set your model to train mode.\n","        loss_record = []\n","\n","        # tqdm is a package to visualize your training progress.\n","        train_pbar = tqdm(train_loader, position=0, leave=True)\n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()               # Set gradient to zero.\n","            x, y = x.to(device), y.to(device)       # Move your data to device. \n","            x = x.reshape(64, 79, 1)\n","            pred = model(x)             \n","            loss = criterion(pred, y)\n","            loss.backward()                  # Compute gradient(backpropagation).\n","            optimizer.step()                  # Update parameters.\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","            \n","            # Display current epoch number and loss on tqdm progress bar.\n","            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n","            train_pbar.set_postfix({'loss': loss.detach().item()})\n","\n","        mean_train_loss = sum(loss_record)/len(loss_record)\n","        writer.add_scalar('Loss/train', mean_train_loss, epoch)\n","\n","        model.eval() # Set your model to evaluation mode.\n","        loss_record = []\n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","\n","            loss_record.append(loss.item())\n","            \n","        mean_valid_loss = sum(loss_record)/len(loss_record)\n","        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n","        writer.add_scalar('Loss/valid', mean_valid_loss, epoch)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config['save_path']) # Save your best model\n","            print('Saving model with loss {:.3f}...'.format(best_loss))\n","            early_stop_count = 0\n","        else: \n","            early_stop_count += 1\n","\n","        if early_stop_count >= config['early_stop']:\n","            print('\\nModel is not improving, so we halt the training session.')\n","            print('Final model loss: {:.3f}.'.format(best_loss))\n","            return\n","    print('Final model loss: {:.3f}.'.format(best_loss))"],"metadata":{"id":"NZY3L3BOJp1m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","config = {\n","    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n","    'select_all': False,   # Whether to use all features.\n","    'valid_ratio': 0.2,   # validation_size = train_size * valid_ratio\n","    'n_epochs': 6000,     # Number of epochs.            \n","    'batch_size': 64, \n","    'learning_rate': 1e-5,              \n","    'early_stop': 600,    # If model has not improved for this many consecutive epochs, stop training.     \n","    'save_path': './models/model.ckpt'  # Your model will be saved here.\n","}"],"metadata":{"id":"1-NAXqxlJrte"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set seed for reproducibility\n","same_seed(config['seed'])\n","\n","\n","# train_data size: 2699 x 118 (id + 37 states + 16 features x 5 days) \n","# test_data size: 1078 x 117 (without last day's positive rate)\n","train_data, test_data = pd.read_csv('./covid.train.csv').values, pd.read_csv('./covid.test.csv').values\n","train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n","\n","# Print out the data size.\n","print(f\"\"\"train_data size: {train_data.shape} \n","valid_data size: {valid_data.shape} \n","test_data size: {test_data.shape}\"\"\")\n","\n","# Select features\n","x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n","print(train_data[0:1,])\n","print(x_train[0:1,])\n","\n","# Print out the number of features.\n","print(f'number of features: {x_train.shape[1]}')\n","\n","train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n","                                            COVID19Dataset(x_valid, y_valid), \\\n","                                            COVID19Dataset(x_test)\n","\n","# Pytorch data loader loads pytorch dataset into batches.\n","train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veGo3IAZJx_t","executionInfo":{"status":"ok","timestamp":1645549992260,"user_tz":-480,"elapsed":638,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"c02ca89b-85e5-4fd5-c1b6-04b4f66a9e78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_data size: (2160, 118) \n","valid_data size: (539, 118) \n","test_data size: (1078, 117)\n","[[6.96000000e+02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n","  0.00000000e+00 0.00000000e+00 5.79090500e-01 5.85951500e-01\n","  8.05311800e+00 5.18962710e+00 8.41981777e+01 7.22943860e+00\n","  2.71227669e+01 6.26506151e+01 2.84817643e+01 3.82629893e+01\n","  1.37898226e+01 5.19101070e+00 1.09628038e+01 9.09377820e+00\n","  3.79826208e+01 3.37470910e+00 5.61994800e-01 5.62395700e-01\n","  8.00968700e+00 5.15822410e+00 8.40298387e+01 7.22602760e+00\n","  2.76996676e+01 6.29006465e+01 2.83891562e+01 3.81773232e+01\n","  1.38840798e+01 5.21680020e+00 1.08047601e+01 9.14013360e+00\n","  3.77632501e+01 2.90923200e+00 5.51045300e-01 5.58497300e-01\n","  8.15762100e+00 5.30857490e+00 8.39093312e+01 7.47796010e+00\n","  2.76056600e+01 6.26574828e+01 2.83441173e+01 3.80962865e+01\n","  1.38121073e+01 5.23712650e+00 1.09066268e+01 9.32090050e+00\n","  3.76801048e+01 3.00077260e+00 5.27639600e-01 5.33486800e-01\n","  8.20413900e+00 5.36841750e+00 8.38027259e+01 7.62548100e+00\n","  2.75796219e+01 6.23436389e+01 2.82653147e+01 3.81657677e+01\n","  1.40387333e+01 5.27375770e+00 1.06949615e+01 9.43190520e+00\n","  3.71549229e+01 3.10289950e+00 5.35871000e-01 5.47987400e-01\n","  7.97297000e+00 5.27335580e+00 8.34627434e+01 7.67030240e+00\n","  2.71711091e+01 6.23769315e+01 2.81713480e+01 3.79840240e+01\n","  1.37717414e+01 5.47741830e+00 1.05732841e+01 9.36138560e+00\n","  3.72386251e+01 3.71092910e+00]]\n","[[ 0.5790905  0.5619948  0.5510453  0.5276396  0.535871   0.5859515\n","   0.5623957  0.5584973  0.5334868  0.5479874  8.053118   8.009687\n","   8.157621   8.204139   7.97297    5.1896271  5.1582241  5.3085749\n","   5.3684175  5.2733558 84.1981777 84.0298387 83.9093312 83.8027259\n","  83.4627434  7.2294386  7.2260276  7.4779601  7.625481   7.6703024\n","  27.1227669 27.6996676 27.60566   27.5796219 27.1711091 62.6506151\n","  62.9006465 62.6574828 62.3436389 62.3769315 28.4817643 28.3891562\n","  28.3441173 28.2653147 28.171348  38.2629893 38.1773232 38.0962865\n","  38.1657677 37.984024  13.7898226 13.8840798 13.8121073 14.0387333\n","  13.7717414  5.1910107  5.2168002  5.2371265  5.2737577  5.4774183\n","  10.9628038 10.8047601 10.9066268 10.6949615 10.5732841  9.0937782\n","   9.1401336  9.3209005  9.4319052  9.3613856 37.9826208 37.7632501\n","  37.6801048 37.1549229 37.2386251  3.3747091  2.909232   3.0007726\n","   3.1028995]]\n","number of features: 79\n"]}]},{"cell_type":"code","source":["model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n","trainer(train_loader, valid_loader, model, config, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"x5I3-DLpJ_q9","executionInfo":{"status":"error","timestamp":1645549992262,"user_tz":-480,"elapsed":8,"user":{"displayName":"Alex Hsu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg-_LAsRtx7Q0vHVneMNkZjptDpiYQG8WbyiXc74A=s64","userId":"18047903736792651990"}},"outputId":"a8664f68-16ce-4fa0-c4a7-d0a2bbbee134"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/34 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-86-fab626c697bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMy_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put your model and data on the same computation device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-83-77ad512abf6f>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train_loader, valid_loader, model, config, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# Move your data to device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m79\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Compute gradient(backpropagation).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-81-9468c7cc759b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, 1) -> (B)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    297\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 298\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1). Kernel size: (5). Kernel size can't be greater than actual input size"]}]},{"cell_type":"code","source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/"],"metadata":{"id":"TNOjf8oIKCCi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_pred(preds, file):\n","    ''' Save predictions to specified file '''\n","    with open(file, 'w') as fp:\n","        writer = csv.writer(fp)\n","        writer.writerow(['id', 'tested_positive'])\n","        for i, p in enumerate(preds):\n","            writer.writerow([i, p])\n","\n","model = My_Model(input_dim=x_train.shape[1]).to(device)\n","model.load_state_dict(torch.load(config['save_path']))\n","preds = predict(test_loader, model, device) \n","save_pred(preds, 'pred.csv') "],"metadata":{"id":"yqFcfdScKECt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"pred.csv\")"],"metadata":{"id":"YTBacgWbKHWf"},"execution_count":null,"outputs":[]}]}